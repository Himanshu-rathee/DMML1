names <- lang.list$`1 language`$GEO
lang.list <- lapply(lang.list, removeColumn)
lang.dist <- data.frame(`No languages` = skills.list$`No languages`, `One language` = skills.list$`1 language`, `Two language` =skills.list$`2 languages`, `Three language or more` = skills.list$`3 languages or more`)
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- skills[,- c(3,4,5)]
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- lang[,- c(3,4,5)]
lang$N_LANG <- as.factor(lang$N_LANG)
lang.list <- split(lang , lang$N_LANG)
removeColumn <- function(df) {
df <- df[,- c(1,2)]
return(df)
}
names <- lang.list$`1 language`$GEO
lang.list <- lapply(lang.list, removeColumn)
lang.dist <- data.frame(`No languages` = skills.list$`No languages`, `One language` = skills.list$`1 language`, `Two language` =skills.list$`2 languages`, `Three language or more` = skills.list$`3 languages or more`)
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- lang[,- c(3,4,5)]
lang$N_LANG <- as.factor(lang$N_LANG)
lang.list <- split(lang , lang$N_LANG)
removeColumn <- function(df) {
df <- df[,- c(1,2)]
return(df)
}
names <- lang.list$`1 language`$GEO
lang.list <- lapply(lang.list, removeColumn)
lang.dist <- data.frame(`No languages` = lang.list$`No languages`, `One language` = lang.list$`1 language`, `Two language` =lang.list$`2 languages`, `Three language or more` = lang.list$`3 languages or more`)
row.names(lang.dist) <- names
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(skills)
str(lang)
str(skills)
skills <- skills[,- c(1,3,4,5)]
str(skills)
View(skills)
skills.sorted = skills[order(rownames(skills)),]
View(skills.sorted)
lang.dist = lang.dist[order(rownames(lang.dist)),]
View(lang.dist)
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(skills)
skills <- skills[,- c(1,3,4,5)]
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
colnames(skills) <- skills$GEO
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- lang[,- c(3,4,5)]
lang$N_LANG <- as.factor(lang$N_LANG)
lang.list <- split(lang , lang$N_LANG)
removeColumn <- function(df) {
df <- df[,- c(1,2)]
return(df)
}
names <- lang.list$`1 language`$GEO
lang.list <- lapply(lang.list, removeColumn)
lang.dist <- data.frame(`No languages` = lang.list$`No languages`, `One language` = lang.list$`1 language`, `Two language` =lang.list$`2 languages`, `Three language or more` = lang.list$`3 languages or more`)
row.names(lang.dist) <- names
lang.dist = lang.dist[order(rownames(lang.dist)),]
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(skills)
colnames(skills) <- skills$GEO
row.names(skills) <- skills$GEO
skills <- skills[,- c(1,2,3,4,5)]
skills = skills[order(rownames(skills)),]
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(skills)
row.names(skills) <- skills$GEO
skills <- skills[,- c(1,3,4,5)]
View(skills)
skills = skills[order(rownames(skills)),]
View(skills)
names(lang.dist)
row.names(lang.dist)
lang.dist <- row.names(lang.dist)
lang <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/edat_aes_l21/edat_aes_l21_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(lang)
lang <- lang[,- c(3,4,5)]
lang$N_LANG <- as.factor(lang$N_LANG)
lang.list <- split(lang , lang$N_LANG)
removeColumn <- function(df) {
df <- df[,- c(1,2)]
return(df)
}
names <- lang.list$`1 language`$GEO
lang.list <- lapply(lang.list, removeColumn)
lang.dist <- data.frame(`No languages` = lang.list$`No languages`, `One language` = lang.list$`1 language`, `Two language` =lang.list$`2 languages`, `Three language or more` = lang.list$`3 languages or more`)
row.names(lang.dist) <- names
lang.dist = lang.dist[order(rownames(lang.dist)),]
lang.dist$GEO <- row.names(lang.dist)
View(lang.dist)
skills <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/xxx/isoc_sk_dskl_i/isoc_sk_dskl_i_1_Data.csv", stringsAsFactors = FALSE, na.strings = ":")
str(skills)
row.names(skills) <- skills$GEO
skills <- skills[,- c(1,3,4,5)]
skills = skills[order(rownames(skills)),]
View(skills)
merged <- merge(lang.dist, skills, by.x="GEO", by.y="GEO")
View(merged)
View(merged)
merged <- merged[- c(34),]
View(merged)
library(psych)
cor(merged)
psych::pairs.panels(merged)
str(merged)
library(fpp2)
library(tseries)
# Question 1
pigs
# Question 1
is.data.frame(pigs)
# Question 1
is.matrix(pigs)
# Question 1
is.list(pigs)
# Question 1
is.data.frame(pigs)
# Question 1
pigs
# Question 1
is.array(pigs)
# Question 1
data.class(pigs)
# Question 1
pigs
autoplot(pigs)
fcast.ses <- ses(pigs, h=4)
summary(fcast.ses)
# Question 2
#a
bicoal
autoplot(bicoal)
ggtsdisplay(bicoal)
#b
coalfit <- arima(bicoal, order = c(4,0,0))
checkresiduals(coalfit)
forecast(coalfit, h=3)
summary(coalfit)
# Question 3
wmurders
autoplot(wmurders)
ggtsdisplay(wmurders)
remove(list = ls())
library(psych)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/GrossValueAdded.csv")
pairs.panels(data)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_004546120.csv")
pairs.panels(data)
pairs.panels(data)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_004546120.csv")
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_005306324.csv")
pairs.panels(data)
View(data)
autoplot(data$Total.Value.Added)
plot(data$Total.Value.Added)
hist(data$Total.Value.Added)
hist(log(data$Total.Value.Added))
abline()
lines(density(data$Total.Value.Added))             # add a density estimate with defaults
lines(log(density(data$Total.Value.Added)))             # add a density estimate with defaults
lines(density(log(data$Total.Value.Added)))             # add a density estimate with defaults
lines(density(log(data$Total.Value.Added), adjust=2), lty="dotted")
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_005306324.csv")
pairs.panels(data)
data1 <- data
data1$Total.Value.Added <- log(data1$Total.Value.Added)
View(data1)
View(data)
pairs.panels(data1)
View(data)
library(ggplot2)
library(ggplot2movies)
# data, aesthetics
pl <- ggplot(movies, aes(x=rating))
# geometery : Histograms basic
pl.hist <- pl + geom_histogram()
print(pl.hist)
# geometery : Histograms binwidth, coor, fill, alpha (for transperancy)
pl.hist <- pl + geom_histogram(binwidth = 0.1, color = 'blue', fill = 'yellow', alpha = 0.4)
print(pl.hist)
# lables
pl.lables <- pl.hist + xlab('Movie Rating') + ylab('Count')
print(pl.lables)
# title
pl.title <- pl.lables + ggtitle('Movie Rating Plot')
print(pl.title)
# fill based on color
pl.hist <- pl + geom_histogram(binwidth = 0.1, aes(fill=..count..))
print(pl.hist)
# lables
pl.lables <- pl.hist + xlab('Movie Rating') + ylab('Count')
print(pl.lables)
# title
pl.title <- pl.lables + ggtitle('Movie Rating Plot')
print(pl.title)
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
View(data)
View(data)
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
remove(list = ls())
bank <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Bank.CSV")
View(bank)
View(bank)
bank.fit <- glm(Direct~Balance, data = bank, family = "binary")
bank.fit <- glm(Direct~Balance, data = bank, family = "binomial")
summary(bank.fit)
bank.fit$coefficients
exp(bank.fit$coefficients)
bank <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
movie <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
remove(list = ls())
movie <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
View(movie)
library(haven)
movie <- read_sav("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
View(movie)
summary(movie)
movie.fit <- glm(Profit~Budjet+Theaters+Opinion, data = movie, family = "binomial")
movie.fit <- glm(Profit~Budget+Theaters+Opinion, data = movie, family = "binomial")
summary(movie.fit)
movie.fit$coefficients
exp(movie.fit$coefficients)
install.packages("ResourceSelection")
library(ResourceSelection)
hoslem.test(movie.fit)
hoslem.test(movie$Profit,movie.fit, g = 10)
lake <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Lakeland.CSV")
summary(lake)
lake <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Lakeland.CSV")
summary(lake)
lake.fit <- glm(Profit~Budget+Theaters+Opinion, data = lake, family = "binomial")
View(lake)
lake.fit <- glm(Return~Program+GPA, data = lake, family = "binomial")
summary(lake.fit)
lake.fit$coefficients
exp(lake.fit$coefficients)
lake.fitG <- glm(Return~GPA, data = lake, family = "binomial")
summary(lake.fitG)
predict(object = lake.fit, c(2.5,0))
predict(object = lake.fit, data.frame(c(2.5,0))
predict(object = lake.fit, data.frame(c(2.5,0)))
st <- predict(object = lake.fit, data.frame(c(2.5,0)))
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
# sorting the data
data <- data[order(data$Year),]
row.names(data) <- 1:49
# creating time series data and analysing
gdp <- ts(data = data$Gross.Domestic.Product..GDP., start = 1970, end = 2018, frequency = 1)
summary(gdp)
summary(gdp)
source('~/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/TimeSeries_final.R', echo=TRUE)
checkresiduals(ddgdp.2)
checkresiduals(ddgdp.3.auto)
checkresiduals(ddgdp.2)
checkresiduals(gdp.3.holt.d)
ddgdp.2
checkresiduals(ddgdp.2)
par(mfrow = c(2,2))
# checking the plots - examining the error, trend, seasonality
plot(gdp, main = "Normal")
library(fpp2)
# smotthing the plot for checking Moving average
plot(ma(gdp,3), main = "q = 3")
plot(ma(gdp,5), main = "q = 5")
plot(ma(gdp,7), main = "q = 7")
# Models Expential Smoothing
par(mfrow = c(1,1))
# Holts Linear Trend Model 2 (level + trend)-
gdp.2.ets <- ets(gdp,model = "AAN")
gdp.2.ets
round(accuracy(gdp.2.ets),3)
# Holts Model with damped Trend Model 3 (level + trend + damped)-
gdp.3.holt.d <- holt(gdp, h = 3, damped = TRUE, PI=FALSE)
gdp.3.holt.d
round(accuracy(gdp.3.holt.d),3) ######------BEST ETS-----######
# Auto ETS method Model
gdp.ets <- ets(gdp, model = "ZZZ")
gdp.ets
round(accuracy(gdp.ets),3)
autoplot(gdp)
# checking best number of difference in time series
ndiffs(gdp) # 2
# diff = 1
dgdp <- diff(gdp)
autoplot(dgdp)
# checking stationarity
library(tseries)
adf.test(dgdp) # not stationary
autoplot(dgdp)
# Chossing p and q value
ggtsdisplay(ddgdp)
# Chossing p and q value
ggtsdisplay(ddgdp, main = "asdf")
# Chossing p and q value
ggtsdisplay(ddgdp, main = "Difference = 2")
# Checking auto ARIMA
ddgdp.3.auto <- auto.arima(gdp)
ddgdp.3.auto
# Auto ETS method Model
gdp.ets <- ets(gdp, model = "ZZZ")
gdp.ets
# Holts Linear Trend Model 2 (level + trend)-
gdp.2.ets <- ets(gdp,model = "AAN")
gdp.2.ets
round(accuracy(gdp.2.ets),3)
# checking best number of difference in time series
ndiffs(gdp) # 2
adf.test(dgdp) # not stationary
gdp.3.holt.d
# Holts Model with damped Trend Model 3 (level + trend + damped)-
gdp.3.holt.d <- holt(gdp, h = 3, damped = TRUE, PI=FALSE)
gdp.3.holt.d
round(accuracy(gdp.3.holt.d),3) ######------BEST ETS-----######
round(accuracy(gdp.3.holt.d),2) ######------BEST ETS-----######
round(accuracy(ddgdp.2),2) #####-------BEST---------############
ddgdp.2
summary(ddgdp.2)
checkresiduals(ddgdp.2)
# Evaluating model
par(mfrow = c(1,1))
qqnorm(ddgdp.2$residuals,main = "Arima (p,d,q) = (4,2,0)")
qqline(ddgdp.2$residuals)
Box.test(ddgdp.2, type = "Ljung-Box")
Box.test(ddgdp.2$residuals, type = "Ljung-Box")
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/L5_house/")
remove(list = ls())
library(data.table)
library(boot)
library(fpp2)
# reading the raw csv file
house <- fread("HousePrices_HalfMil.csv")
house.boxplot <- boxplot(house$Prices, main = "Box plot", ylab = "House prices")
# removing outliers to make more genarlised  model
house.boxplot$out
house <- subset(house, ! house$Prices %in% house.boxplot$out)
house.boxplot <- boxplot(house$Prices, main = "Box plot", ylab = "House prices")
house.boxplot$out
hist(house$Prices,
col = "orange",
border = "black",
prob = TRUE,
xlab = "House prices",
main = "Histogram")
lines(density(house$Prices),
lwd = 2,
col = "chocolate3")
# re-numbering the rows names
row.names(house) <- 1:499984
base.fit <- glm(Prices ~ ., data = house)
summary(base.fit) # -16807578
base.fit2 <- step(base.fit)
base.k10.fit2.err <- cv.glm(data = house,glmfit = base.fit2, K = 10)
base.k10.fit2.err$delta# 0.1001
base.fit3 <- update(base.fit2, ~ . - `Swiming Pool` - Garden)
summary(base.fit3) # -16807262
base.k10.fit3.err <- cv.glm(data = house,glmfit = base.fit3, K = 10)
base.k10.fit3.err$delta[2]# 0.1001
base.k10.fit3.err$delta# 1.474115e-16
# cheking correlation
cor(house)
# making a new df with only correlated columns
chouse <- house
chouse <- chouse[,-c(2,3,6,10,11,14,15)]
chouse.colnames <-colnames(chouse)
chouse.colnames[3] <- "White_Marbel"
chouse.colnames[4] <- "Indian_Marbel"
colnames(chouse) <- chouse.colnames
# checking correlation
cor(chouse)
# linear model
house.fit1 <- glm(Prices ~ . + White_Marbel:Indian_Marbel , data = chouse)
summary(house.fit1) #8882283
# adding the correlation independent variabels
house.fit2 <- update(house.fit1, ~ . - White_Marbel:Indian_Marbel)
summary(house.fit2) #8882283
house.k10.fit2.err <- cv.glm(data = chouse,glmfit = house.fit2, K = 10)
house.k10.fit2.err$delta# 0.1001
summary(house)
# checking correlation
cor.test(chouse)
# checking correlation
cor(chouse)
summary(house.fit2) #8882283
summary(base.fit3) # -16807262
accuracy(base.fit3)
accuracy(house.fit2)
#checking r2
house.fit2.lm <- lm(Prices ~ ., data = chouse)
summary(house.fit2)
summary(house.fit2.lm)
summary(base.fit3) # -16807262
#checking r2
base.fit2.lm <- lm(formula = Prices ~ Area + Garage + FirePlace + Baths + `White Marble` +
`Black Marble` + Floors + City + Solar + Electric + Fiber +
`Glass Doors`, data = house)
summary(base.fit2.lm)
summary(house.fit2.lm) #
# adding the polynomial independent variabels
house.fit3 <- update(house.fit2, ~ . + I(Area,2) + I(Baths,2) + I(White_Marbel,2) + I(Indian_Marbel,2) + I(Floors,2) + I(City,2) + + I(`Glass Doors`,2))
# adding the polynomial independent variabels
house.fit3 <- update(house.fit2, ~ . + I(Area,2) + I(Baths,2) + I(White_Marbel^2) + I(Indian_Marbel^2) + I(Floors^2) + I(City^2) + + I(`Glass Doors`^2))
# adding the polynomial independent variabels
house.fit3 <- update(house.fit2, ~ . + I(Area^2) + I(Baths^2) + I(White_Marbel^2) + I(Indian_Marbel^2) + I(Floors^2) + I(City^2) + + I(`Glass Doors`^2))
summary(house.fit3) #8882283
# checking the best fit
house.fit2.bestFit2 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 5)
library(car)
library(leaps)
# checking the best fit
house.fit2.bestFit2 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 5)
par(mfrow = c(1,1))
# checking the best fit
house.fit2.bestFit2 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 8)
subsets(house.fit2.bestFit2, statistic = "adjr2", max.size = 8, min.size = 1)
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/L5_house/")
remove(list = ls())
library(data.table)
library(boot)
library(fpp2)
library(car)
library(leaps)
# reading the raw csv file
house <- fread("HousePrices_HalfMil.csv")
house.boxplot <- boxplot(house$Prices, main = "Box plot", ylab = "House prices")
house <- subset(house, ! house$Prices %in% house.boxplot$out)
# checking the best fit
house.fit2.bestFit1 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 8)
# making a new df with only correlated columns
chouse <- house
chouse <- chouse[,-c(2,3,6,10,11,14,15)]
chouse.colnames <-colnames(chouse)
chouse.colnames[3] <- "White_Marbel"
chouse.colnames[4] <- "Indian_Marbel"
colnames(chouse) <- chouse.colnames
# checking the best fit
house.fit2.bestFit1 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 8)
par(mfrow = c(1,1))
subsets(house.fit2.bestFit1, statistic = "adjr2", max.size = 8, min.size = 1)
# checking the best fit
house.fit2.bestFit1 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 2, nvmax = 6)
par(mfrow = c(1,1))
subsets(house.fit2.bestFit1, statistic = "adjr2", max.size = 8, min.size = 1)
# checking the best fit
house.fit2.bestFit1 <- regsubsets(Prices ~ Area + Baths + White_Marbel + Indian_Marbel +
Floors + City + Fiber + `Glass Doors`, data = chouse, nbest = 1, nvmax = 6)
par(mfrow = c(1,1))
subsets(house.fit2.bestFit1, statistic = "adjr2", max.size = 8, min.size = 1)
subsets(house.fit2.bestFit1, statistic = "adjr2", max.size = 6, min.size = 1)
# 4 predictors
house.fit4 <- glm(Prices ~ White_Marbel + Floors + City + Fiber, data = chouse)
summary(house.fit4) #8882288
house.k10.fit4.err <- cv.glm(data = chouse,glmfit = house.fit4, K = 10)
house.k10.fit4.err$delta# 3039673
#checking r2
house.fit4.lm <- lm(Prices ~ White_Marbel + Floors + City + Fiber, data = chouse)
summary(house.fit4.lm) # 0.9793
# 5 predictors
house.fit5 <- glm(Prices ~ White_Marbel + Floors + City + Fiber + `Glass Doors`, data = chouse)
summary(house.fit5) #9783831
house.k10.fit5.err <- cv.glm(data = chouse,glmfit = house.fit5, K = 10)
summary(house.fit6) #9783831
house.k10.fit5.err$delta# 3039673
#checking r2
house.fit5.lm <- lm(Prices ~ ., data = chouse)
summary(house.fit5.lm) # 0.9793
summary(house.fit5.lm) # 0.9793
#checking r2
house.fit5.lm <- lm(Prices ~ White_Marbel + Floors + City + Fiber + `Glass Doors`, data = chouse)
summary(house.fit5.lm) # 0.9793
# 6 predictors
house.fit6 <- glm(Prices ~ White_Marbel + Indian_Marbel + Floors + City + Fiber + `Glass Doors`, data = chouse)
summary(house.fit6) #9783831
house.k10.fit6.err <- cv.glm(data = chouse,glmfit = house.fit6, K = 10)
house.k10.fit6.err$delta# 3039673
#checking r2
house.fit6.lm <- lm(Prices ~ White_Marbel + Indian_Marbel + Floors + City + Fiber + `Glass Doors`, data = chouse)
summary(house.fit6.lm) # 0.9793
