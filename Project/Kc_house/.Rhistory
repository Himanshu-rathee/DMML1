# Question 1
is.list(pigs)
# Question 1
is.data.frame(pigs)
# Question 1
pigs
# Question 1
is.array(pigs)
# Question 1
data.class(pigs)
# Question 1
pigs
autoplot(pigs)
fcast.ses <- ses(pigs, h=4)
summary(fcast.ses)
# Question 2
#a
bicoal
autoplot(bicoal)
ggtsdisplay(bicoal)
#b
coalfit <- arima(bicoal, order = c(4,0,0))
checkresiduals(coalfit)
forecast(coalfit, h=3)
summary(coalfit)
# Question 3
wmurders
autoplot(wmurders)
ggtsdisplay(wmurders)
remove(list = ls())
library(psych)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/GrossValueAdded.csv")
pairs.panels(data)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_004546120.csv")
pairs.panels(data)
pairs.panels(data)
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_004546120.csv")
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_005306324.csv")
pairs.panels(data)
View(data)
autoplot(data$Total.Value.Added)
plot(data$Total.Value.Added)
hist(data$Total.Value.Added)
hist(log(data$Total.Value.Added))
abline()
lines(density(data$Total.Value.Added))             # add a density estimate with defaults
lines(log(density(data$Total.Value.Added)))             # add a density estimate with defaults
lines(density(log(data$Total.Value.Added)))             # add a density estimate with defaults
lines(density(log(data$Total.Value.Added), adjust=2), lty="dotted")
data <- read.csv("/Users/sobil/Downloads/Stats_Data_sets/Final/UNdata_Export_20200318_005306324.csv")
pairs.panels(data)
data1 <- data
data1$Total.Value.Added <- log(data1$Total.Value.Added)
View(data1)
View(data)
pairs.panels(data1)
View(data)
library(ggplot2)
library(ggplot2movies)
# data, aesthetics
pl <- ggplot(movies, aes(x=rating))
# geometery : Histograms basic
pl.hist <- pl + geom_histogram()
print(pl.hist)
# geometery : Histograms binwidth, coor, fill, alpha (for transperancy)
pl.hist <- pl + geom_histogram(binwidth = 0.1, color = 'blue', fill = 'yellow', alpha = 0.4)
print(pl.hist)
# lables
pl.lables <- pl.hist + xlab('Movie Rating') + ylab('Count')
print(pl.lables)
# title
pl.title <- pl.lables + ggtitle('Movie Rating Plot')
print(pl.title)
# fill based on color
pl.hist <- pl + geom_histogram(binwidth = 0.1, aes(fill=..count..))
print(pl.hist)
# lables
pl.lables <- pl.hist + xlab('Movie Rating') + ylab('Count')
print(pl.lables)
# title
pl.title <- pl.lables + ggtitle('Movie Rating Plot')
print(pl.title)
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
View(data)
View(data)
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
remove(list = ls())
bank <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Bank.CSV")
View(bank)
View(bank)
bank.fit <- glm(Direct~Balance, data = bank, family = "binary")
bank.fit <- glm(Direct~Balance, data = bank, family = "binomial")
summary(bank.fit)
bank.fit$coefficients
exp(bank.fit$coefficients)
bank <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
movie <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
remove(list = ls())
movie <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
View(movie)
library(haven)
movie <- read_sav("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/65_Movies_Profit.sav")
View(movie)
summary(movie)
movie.fit <- glm(Profit~Budjet+Theaters+Opinion, data = movie, family = "binomial")
movie.fit <- glm(Profit~Budget+Theaters+Opinion, data = movie, family = "binomial")
summary(movie.fit)
movie.fit$coefficients
exp(movie.fit$coefficients)
install.packages("ResourceSelection")
library(ResourceSelection)
hoslem.test(movie.fit)
hoslem.test(movie$Profit,movie.fit, g = 10)
lake <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Lakeland.CSV")
summary(lake)
lake <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Lab8/Lakeland.CSV")
summary(lake)
lake.fit <- glm(Profit~Budget+Theaters+Opinion, data = lake, family = "binomial")
View(lake)
lake.fit <- glm(Return~Program+GPA, data = lake, family = "binomial")
summary(lake.fit)
lake.fit$coefficients
exp(lake.fit$coefficients)
lake.fitG <- glm(Return~GPA, data = lake, family = "binomial")
summary(lake.fitG)
predict(object = lake.fit, c(2.5,0))
predict(object = lake.fit, data.frame(c(2.5,0))
predict(object = lake.fit, data.frame(c(2.5,0)))
st <- predict(object = lake.fit, data.frame(c(2.5,0)))
remove(list = ls())
# reading the gdp file
data <- read.csv("/Users/sobil/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/GDP_Ireland.csv")
str(data)
summary(data)
# converting the predictor to billion figures
data$Gross.Domestic.Product..GDP. <- data$Gross.Domestic.Product..GDP./1000000000
summary(data)
# sorting the data
data <- data[order(data$Year),]
row.names(data) <- 1:49
# creating time series data and analysing
gdp <- ts(data = data$Gross.Domestic.Product..GDP., start = 1970, end = 2018, frequency = 1)
summary(gdp)
summary(gdp)
source('~/Documents/MSC/Sem 1/Statistics for Data Analytics/Lab/Project/Time-Series/TimeSeries_final.R', echo=TRUE)
checkresiduals(ddgdp.2)
checkresiduals(ddgdp.3.auto)
checkresiduals(ddgdp.2)
checkresiduals(gdp.3.holt.d)
ddgdp.2
checkresiduals(ddgdp.2)
par(mfrow = c(2,2))
# checking the plots - examining the error, trend, seasonality
plot(gdp, main = "Normal")
library(fpp2)
# smotthing the plot for checking Moving average
plot(ma(gdp,3), main = "q = 3")
plot(ma(gdp,5), main = "q = 5")
plot(ma(gdp,7), main = "q = 7")
# Models Expential Smoothing
par(mfrow = c(1,1))
# Holts Linear Trend Model 2 (level + trend)-
gdp.2.ets <- ets(gdp,model = "AAN")
gdp.2.ets
round(accuracy(gdp.2.ets),3)
# Holts Model with damped Trend Model 3 (level + trend + damped)-
gdp.3.holt.d <- holt(gdp, h = 3, damped = TRUE, PI=FALSE)
gdp.3.holt.d
round(accuracy(gdp.3.holt.d),3) ######------BEST ETS-----######
# Auto ETS method Model
gdp.ets <- ets(gdp, model = "ZZZ")
gdp.ets
round(accuracy(gdp.ets),3)
autoplot(gdp)
# checking best number of difference in time series
ndiffs(gdp) # 2
# diff = 1
dgdp <- diff(gdp)
autoplot(dgdp)
# checking stationarity
library(tseries)
adf.test(dgdp) # not stationary
autoplot(dgdp)
# Chossing p and q value
ggtsdisplay(ddgdp)
# Chossing p and q value
ggtsdisplay(ddgdp, main = "asdf")
# Chossing p and q value
ggtsdisplay(ddgdp, main = "Difference = 2")
# Checking auto ARIMA
ddgdp.3.auto <- auto.arima(gdp)
ddgdp.3.auto
# Auto ETS method Model
gdp.ets <- ets(gdp, model = "ZZZ")
gdp.ets
# Holts Linear Trend Model 2 (level + trend)-
gdp.2.ets <- ets(gdp,model = "AAN")
gdp.2.ets
round(accuracy(gdp.2.ets),3)
# checking best number of difference in time series
ndiffs(gdp) # 2
adf.test(dgdp) # not stationary
gdp.3.holt.d
# Holts Model with damped Trend Model 3 (level + trend + damped)-
gdp.3.holt.d <- holt(gdp, h = 3, damped = TRUE, PI=FALSE)
gdp.3.holt.d
round(accuracy(gdp.3.holt.d),3) ######------BEST ETS-----######
round(accuracy(gdp.3.holt.d),2) ######------BEST ETS-----######
round(accuracy(ddgdp.2),2) #####-------BEST---------############
ddgdp.2
summary(ddgdp.2)
checkresiduals(ddgdp.2)
# Evaluating model
par(mfrow = c(1,1))
qqnorm(ddgdp.2$residuals,main = "Arima (p,d,q) = (4,2,0)")
qqline(ddgdp.2$residuals)
Box.test(ddgdp.2, type = "Ljung-Box")
Box.test(ddgdp.2$residuals, type = "Ljung-Box")
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/")
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
opts_chunk$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
str(kc_house)
summary(kc_house)
kc_house <- kc_house[,-c(1)]
kc_house <- kc_house[,-c(15,16,17)]
kc_house <- kc_house[,-c(15,16)]
apply(X = kc_house,MARGIN =  2, FUN = function(col) any(is.na(col))) # no NAs
table(kc_house$bedrooms)
kc_house <- kc_house[kc_house$bedrooms != 33,]
table(kc_house$bathrooms)
table(kc_house$view)
row.names(kc_house) <- 1:21612
kc_house$date <- as.Date(kc_house$date, format = "%Y%m%d")
summary(kc_house$date)
kc_house <- kc_house[,-c(1)]
table(kc_house$waterfront)
kc_house$waterfront <- as.factor(kc_house$waterfront)
library(boot)
library(car)
library(leaps)
library(psych)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
str(kc_house)
summary(kc_house)
kc_house <- kc_house[,-c(1)]
kc_house <- kc_house[,-c(15,16,17)]
kc_house <- kc_house[,-c(15,16)]
apply(X = kc_house,MARGIN =  2, FUN = function(col) any(is.na(col))) # no NAs
table(kc_house$bedrooms)
kc_house <- kc_house[kc_house$bedrooms != 33,]
table(kc_house$bathrooms)
table(kc_house$view)
row.names(kc_house) <- 1:21612
kc_house$date <- as.Date(kc_house$date, format = "%Y%m%d")
summary(kc_house$date)
kc_house <- kc_house[,-c(1)]
table(kc_house$waterfront)
kc_house$waterfront <- as.factor(kc_house$waterfront)
library(boot)
library(car)
library(leaps)
library(psych)
pairs.panels(kc_house)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
str(kc_house)
summary(kc_house)
kc_house <- kc_house[,-c(1)]
kc_house <- kc_house[,-c(15,16,17)]
kc_house <- kc_house[,-c(15,16)]
apply(X = kc_house,MARGIN =  2, FUN = function(col) any(is.na(col))) # no NAs
table(kc_house$bedrooms)
kc_house <- kc_house[kc_house$bedrooms != 33,]
table(kc_house$bathrooms)
table(kc_house$view)
row.names(kc_house) <- 1:21612
kc_house$date <- as.Date(kc_house$date, format = "%Y%m%d")
summary(kc_house$date)
kc_house <- kc_house[,-c(1)]
table(kc_house$waterfront)
kc_house$waterfront <- as.factor(kc_house$waterfront)
library(boot)
library(car)
library(leaps)
library(psych)
pairs.panels(kc_house)
house.fit1 <- glm(price ~ ., data = kc_house)
summary(house.fit1)
house.fit2 <- step(house.fit1)
summary(house.fit2)
house.fit3 <- update(house.fit2, ~ . + bedrooms:bathrooms + bedrooms:grade + bedrooms:sqft_above + bedrooms:sqft_living + bathrooms:grade + bathrooms:sqft_above + sqft_above:sqft_living + grade:sqft_living + bathrooms:sqft_living + floors:sqft_living + view:sqft_living + floors:condition + floors:grade + floors:sqft_above + waterfront:view + view:grade)
summary(house.fit3)
house.fit4 <- step(house.fit3)
summary(house.fit4)
house.fit5 <- update(house.fit2, ~ . - floors)
summary(house.fit5)
bstFits1 <- regsubsets(price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated, data = kc_house, nbest = 1, nvmax = 6)
View(kc_house)
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/")
source("Kc_Import_Explore_Clean.R")
View(kc_house)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
kc_house <- read.csv("kc_house_data.csv", stringsAsFactors = FALSE)
str(kc_house)
summary(kc_house)
kc_house <- kc_house[,-c(1)]
kc_house <- kc_house[,-c(18,16,17)]
kc_house <- kc_house[,-c(17,16)]
apply(X = kc_house,MARGIN =  2, FUN = function(col) any(is.na(col))) # no NAs
table(kc_house$bedrooms)
kc_house <- kc_house[kc_house$bedrooms != 33,]
table(kc_house$bathrooms)
table(kc_house$view)
row.names(kc_house) <- 1:21612
kc_house$date <- as.Date(kc_house$date, format = "%Y%m%d")
summary(kc_house$date)
kc_house <- kc_house[,-c(1)]
table(kc_house$waterfront)
kc_house$waterfront <- as.factor(kc_house$waterfront)
View(kc_house)
bstFits1 <- regsubsets(price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated, data = kc_house, nbest = 1, nvmax = 6)
par(mfrow = c(1,1))
subsets(bstFits1, statistic = "adjr2", max.size = 6)
par(mfrow = c(1,1))
#subsets(bstFits1, statistic = "adjr2", max.size = 6)
plot(bstFits1, scale = "adjr2")
bstFits1 <- regsubsets(price ~ bedrooms+bathrooms+sqft_living+sqft_lot+floors+waterfront+view+condition+grade+sqft_above+sqft_basement+yr_built+yr_renovated, data = kc_house, nbest = 1, nvmax = 6)
par(mfrow = c(1,1))
#subsets(bstFits1, statistic = "adjr2", max.size = 6)
plot(bstFits1, scale = "adjr2")
par(mfrow = c(2,2))
plot(house.k10.4)
house.k10.4 <- glm(price ~ sqft_living + waterfront + yr_renovated + grade, data = kc_house)
summary(house.k10.4) # 596532
house.k10.4.err <- cv.glm(data = kc_house,glmfit = house.k10.4, K = 10)
round(house.k10.4.err$delta[1], 4) # 56952103727
par(mfrow = c(2,2))
plot(house.k10.4)
house.k10.4.lm <- lm(price ~ sqft_living + waterfront + yr_renovated + grade, data = kc_house)
summary(house.k10.4.lm)
library(ggplot2)
library(ggthemes)
theme_set(theme_gdocs())
ggplot(kc_house, aes(x=price)) + geom_histogram(bins = 10, color = 'blue', aes(fill=..count..), alpha = 0.4) + xlab('House Price') + ylab('Count') + ggtitle('House Price distribution Plot')
par(mfrow = c(1,2))
hist(kc_house$price,
col="orange",
border="black",
prob = TRUE,
xlab = "House prices",
main = "Histogram")
lines(density(kc_house$price),
lwd = 2,
col = "chocolate3") # not distributed normally - right skewed
plot(kc_house$price, main = "Scatter plot", ylab = "House prices")
# covert to log
hist(log(kc_house$price),
col="orange",
border="black",
prob = TRUE,
xlab = "House prices",
main = "Histogram")
lines(density(log(kc_house$price)),
lwd = 2,
col = "chocolate3") # not distributed normally
plot(log(kc_house$price), main = "Scatter plot", ylab = "House prices")
kc_house_log <- kc_house
kc_house_log$price <- log(kc_house_log$price)
summary(kc_house_log)
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/")
source("Kc_Import_Explore_Clean.R")
source("kc_Transform_log.R")
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
library(RWeka)
library(rpart)
library(rpart.plot)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
library(RWeka)
library(rpart)
library(rpart.plot)
source("Kc_Import_Explore_Clean.R")
indx <- createDataPartition(kc_house$price, p = 0.8, list = FALSE)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
set.seed(123)
library(RWeka)
library(rpart)
library(rpart.plot)
library(caret)
source("Kc_Import_Explore_Clean.R")
indx <- createDataPartition(kc_house$price, p = 0.8, list = FALSE)
house_train <- kc_house[indx,]
house_test <- kc_house[- indx,]
house.rpart <- rpart(price ~ ., data = house_train)
house.rpart
summary(house.rpart)
rpart.plot(house.rpart, digits = 3)
house.predict.rpart <- predict(house.rpart, house_test)
summary(house.predict.rpart)
summary(house_test$price)
cor(house.predict.rpart, house_test$price) # 0.7396
mae <- function(actual, pred) {
mean(abs(actual-pred))
}
mae(house_test$price, house.predict.rpart) # 160106.7
mae(mean(house_train$price), house.predict.rpart) # 181915.5
house.m5p <- M5P(price ~ . , data = house_train)
house.m5p
summary(house.m5p)
house.predict.m5p <- predict(house.m5p, house_test)
summary(house.predict.m5p)
cor(house.predict.m5p, house_test$price) # 0.6864
mae(house_test$price, house.predict.m5p) # 12137947
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
set.seed(1)
knitr::opts_knit$set(root.dir = '/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/')
remove(list = ls())
set.seed(1)
setwd("/Users/sobil/Documents/MSC/Sem 1/Data Mining & Machine Learning/Project/Kc_house/")
source("Kc_Import_Explore_Clean.R")
library(RWeka)
library(rpart)
library(rpart.plot)
library(caret)
# creating training and testing dataset from exisitng sample
indx <- createDataPartition(kc_house$price, p = 0.8, list = FALSE)
house_train <- kc_house[indx,]
house_test <- kc_house[- indx,]
# Step 3 : Training a model
# regression tree
house.rpart <- rpart(price ~ ., data = house_train)
house.rpart
summary(house.rpart)
# visulazing decision tree
rpart.plot(house.rpart, digits = 3)
# Step 4 : Evaluating model performace
house.predict.rpart <- predict(house.rpart, house_test)
summary(house.predict.rpart)
summary(house_test$price)
# checking correlation
cor(house.predict.rpart, house_test$price) # 0.7396
set.seed(1)
# Step 3 : Training a model
# regression tree
house.rpart <- rpart(price ~ ., data = house_train)
house.rpart
summary(house.rpart)
# visulazing decision tree
rpart.plot(house.rpart, digits = 3)
# Step 4 : Evaluating model performace
house.predict.rpart <- predict(house.rpart, house_test)
summary(house.predict.rpart)
summary(house_test$price)
# checking correlation
cor(house.predict.rpart, house_test$price) # 0.7396
# cheking performace with MAE
mae <- function(actual, pred) {
mean(abs(actual-pred))
}
mae(house_test$price, house.predict.rpart) # 160106.7
mae(mean(house_train$price), house.predict.rpart) # 181915.5
# Step 5 : Improving model
# model tree
house.m5p <- M5P(price ~ . , data = house_train)
house.m5p
summary(house.m5p)
house.predict.m5p <- predict(house.m5p, house_test)
summary(house.predict.m5p)
cor(house.predict.m5p, house_test$price) # 0.6864
mae(house_test$price, house.predict.m5p) # 12137947
house.m5p <- M5P(price ~ . , data = house_train)
house.m5p
#summary(house.m5p)
house.m5p <- M5P(price ~ . , data = house_train)
#house.m5p
summary(house.m5p)
#house.rpart
summary(house.rpart)
house.rpart
#summary(house.rpart)
#house.rpart
summary(house.rpart)
